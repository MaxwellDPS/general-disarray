# SIP AI Assistant Environment Configuration
# ===========================================
# Copy this file to .env and configure for your setup

# HuggingFace token (required for Llama access)
HF_TOKEN=your_huggingface_token_here

# SIP Configuration
SIP_USER=ai-assistant
SIP_PASSWORD=
SIP_DOMAIN=localhost
SIP_PORT=5060
# Uncomment for SIP provider registration:
# SIP_REGISTRAR=sip.yourprovider.com

# LLM Configuration
LLM_BACKEND=vllm
LLM_MODEL=meta-llama/Llama-3.1-70B-Instruct
LLM_BASE_URL=http://localhost:8000/v1

# For smaller VRAM, use:
# LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct

# For Ollama instead of vLLM:
# LLM_BACKEND=ollama
# LLM_BASE_URL=http://localhost:11434

# Whisper Configuration
WHISPER_MODEL=large-v3
# For faster but less accurate:
# WHISPER_MODEL=medium

# ===========================================
# Voice Cloning Configuration
# ===========================================
# Enable voice cloning (uses more VRAM but allows custom voices)
VOICE_CLONING_ENABLED=false

# Voice cloning backend options:
# - xtts: Coqui XTTS v2 (best quality, ~6GB VRAM)
# - chatterbox: Resemble AI's Chatterbox (good balance)
# - openvoice: MyShell OpenVoice (style transfer)
# - fish_speech: Fish Speech (fast, streaming)
VOICE_CLONING_BACKEND=xtts

# Default voice profile to use (leave empty for first available)
VOICE_CLONING_PROFILE=

# Directory for voice profiles
VOICES_DIR=./data/voices

# XTTS specific settings
XTTS_TEMPERATURE=0.7
XTTS_TOP_K=50
XTTS_TOP_P=0.85
XTTS_REPETITION_PENALTY=2.0

# Chatterbox specific settings
CHATTERBOX_EXAGGERATION=0.5
CHATTERBOX_CFG_WEIGHT=0.5

# ===========================================
# Fallback TTS (Piper)
# ===========================================
# Used when voice cloning is disabled or fails
PIPER_MODEL=en_US-amy-medium
PIPER_MODEL_PATH=/opt/piper/models

# Logging
LOG_LEVEL=INFO
# For debugging: LOG_LEVEL=DEBUG

# Data directory (for recordings, logs)
DATA_DIR=./data
