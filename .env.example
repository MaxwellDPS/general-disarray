# SIP AI Assistant - Environment Configuration
# =============================================
# Services:
# - vLLM for LLM
# - Speaches for STT (Whisper) + TTS (Piper/Kokoro)

# Hugging Face Token (for downloading models)
HF_TOKEN=your_huggingface_token_here

# ===================
# LLM Configuration (vLLM)
# ===================
LLM_BACKEND=vllm
LLM_MODEL=openai/gpt-oss-20b

# ===================
# Speaches API (Unified STT + TTS)
# ===================
# The Speaches container provides both Whisper STT and Piper/Kokoro TTS
# via OpenAI-compatible API endpoints

# Model unloading prevention (set in docker-compose.yml):
STT_MODEL_TTL=-1   # Never unload STT model
TTS_MODEL_TTL=-1   # Never unload TTS model
VAD_MODEL_TTL=-1   # Never unload VAD model
# Default is 300 seconds (5 minutes) of idle time before unloading

# ===================
# Whisper STT Settings
# ===================
# Distilled models are much faster
WHISPER_MODEL=Systran/faster-distil-whisper-small.en
WHISPER_LANGUAGE=en

# Compute type for Whisper inference
# Options: auto, int8, int8_float16, int8_float32, float16, float32
# Use 'auto' if you get errors about unsupported compute types
# Use 'int8' for fastest inference on most hardware
WHISPER_COMPUTE_TYPE=auto

# ===================
# TTS Settings (via Speaches API)
# ===================
# TTS Model - Models are auto-downloaded on first use
# Recommended options:
#   speaches-ai/Kokoro-82M-v1.0-ONNX (default, high quality, ~24kHz)
#   speaches-ai/Kokoro-82M-v1.0-ONNX-int8 (faster, slightly lower quality)
#
# For Piper voices, use the full HuggingFace model path:
#   rhasspy/piper-voice-en_US-lessac-medium
#   rhasspy/piper-voice-en_US-amy-medium
#   rhasspy/piper-voice-en_GB-alan-medium
TTS_MODEL=speaches-ai/Kokoro-82M-v1.0-ONNX

# Voice options for Kokoro (see https://huggingface.co/hexgrad/Kokoro-82M):
#   af_heart, af_bella, af_nicole, af_sarah, af_sky (female)
#   am_adam, am_michael (male)
#
# Voice options for Piper (depends on model):
#   Usually the model only has one voice, so this can be left empty
TTS_VOICE=af_heart

# Response format (wav recommended for low latency)
TTS_RESPONSE_FORMAT=wav

# Speech speed (1.0 = normal)
TTS_SPEED=1.0

# ===================
# SIP Configuration
# ===================
SIP_USER=ai-assistant
SIP_PASSWORD=
SIP_DOMAIN=localhost
SIP_PORT=5060
SIP_REGISTRAR=

# ===================
# Voice Interaction
# ===================
# Silence timeout before processing speech (ms)
SILENCE_TIMEOUT_MS=500

# Barge-in detection settings
BARGE_IN_MIN_DURATION=400
BARGE_IN_ENERGY_THRESHOLD=2000

# ===================
# Callback Settings
# ===================
# How long to wait for callback to be answered (seconds)
CALLBACK_RING_TIMEOUT=30

# ===================
# Tempest Weather API
# ===================
# Get your station ID and API token from https://tempestwx.com/settings/tokens
TEMPEST_STATION_ID=
TEMPEST_API_TOKEN=

# ===================
# Logging
# ===================
LOG_LEVEL=INFO

# ===================
# API Server
# ===================
# Port for the REST API (outbound calls, health check)
API_PORT=8080
