# Docker Compose for SIP AI Assistant
# ====================================
# Optimized for GB10/Grace Blackwell with 100GB+ VRAM
#
# Services:
#   - vllm: LLM server (Llama 3.1 70B)
#   - xtts: XTTS2 streaming TTS server  
#   - sip-assistant: Main SIP application

services:
  # ============================================================================
  # vLLM Server - Serves the LLM
  # ============================================================================
  vllm:
    image: nvcr.io/nvidia/vllm:25.11-py3
    container_name: sip-ai-vllm
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
    env_file:
      - .env
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    command: >
      vllm serve
      ${LLM_MODEL:-meta-llama/Llama-3.1-70B-Instruct}
      --port 8000
      --gpu-memory-utilization 0.60
      --max-model-len 8192
      --trust-remote-code
    ports:
      - "8000:8000"
    volumes:
      - ./cache/huggingface-cache:/root/.cache/huggingface
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # ============================================================================
  # XTTS Server - High-quality streaming TTS
  # ============================================================================
  xtts:
    build:
      context: xtts-api
      dockerfile: Dockerfile
    container_name: sip-ai-xtts
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - XTTS_HOST=0.0.0.0
      - XTTS_PORT=8001
      - XTTS_SAMPLE_RATE=24000
      - XTTS_TEMPERATURE=${XTTS_TEMPERATURE:-0.7}
      - XTTS_TOP_K=${XTTS_TOP_K:-50}
      - XTTS_TOP_P=${XTTS_TOP_P:-0.85}
      - XTTS_REPETITION_PENALTY=${XTTS_REPETITION_PENALTY:-2.0}
      - VOICES_DIR=/app/data/voices
    ports:
      - "8001:8001"
    volumes:
      - ./data/voices:/app/data/voices
      - ./cache/xtts-cache:/root/.local/share/tts
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # ============================================================================
  # SIP AI Assistant - Main application
  # ============================================================================
  sip-agent:
    build:
      context: sip-agent/
      dockerfile: Dockerfile
    container_name: sip-ai-assistant
    # network_mode: "host"
    runtime: nvidia
    depends_on:
      vllm:
        condition: service_healthy
      xtts:
        condition: service_healthy
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      # LLM settings
      - LLM_BACKEND=vllm
      - LLM_BASE_URL=http://vllm:8000/v1
      - LLM_MODEL=${LLM_MODEL:-meta-llama/Llama-3.1-70B-Instruct}
      # Whisper settings (standard whisper with CUDA)
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v3}
      - WHISPER_DEVICE=cuda
      - WHISPER_LANGUAGE=en
      # XTTS settings
      - XTTS_API_URL=http://xtts:8001
      - XTTS_DEFAULT_VOICE=${XTTS_DEFAULT_VOICE:-}
      # SIP settings
      - SIP_USER=${SIP_USER:-ai-assistant}
      - SIP_PASSWORD=${SIP_PASSWORD:-}
      - SIP_DOMAIN=${SIP_DOMAIN:-localhost}
      - SIP_PORT=${SIP_PORT:-5060}
      - SIP_REGISTRAR=${SIP_REGISTRAR:-}
      # General
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "5060:5060/udp"
      - "5060:5060/tcp"
      - "10000-10100:10000-10100/udp"  # RTP ports
    volumes:
      - ./data:/app/data
      - ./cache/whisper-cache:/root/.cache/whisper
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped


# ============================================================================
# Volumes
# ============================================================================
# volumes:
#   huggingface-cache:
#     name: sip-ai-hf-cache
#   whisper-cache:
#     name: sip-ai-whisper-cache
#   xtts-cache:
#     name: sip-ai-xtts-cache
#   tiktoken-cache:
#     name: sip-ai-tiktoken-cache


# ============================================================================
# Networks
# ============================================================================
networks:
  default:
    driver: bridge