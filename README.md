# ğŸ“âš¡ General Dissarray
## ğŸ¤– SIP Enabled AI Agent

> ğŸ¤– **ROBO CODED** â€” This project was made with AI and may not be 100% sane. But the code does work! ğŸ‰

A voice-powered AI assistant that answers phone calls, understands natural language, and performs actions like checking weather, setting timers, scheduling callbacks, and more.

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Version](https://img.shields.io/badge/Version-0.1.0-green.svg)](RELEASE.md)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-green.svg)](https://www.python.org/)
[![Runs on DGX Spark](https://img.shields.io/badge/Runs%20on-DGX%20Spark-76B900?logo=nvidia&logoColor=white)](https://www.nvidia.com/en-us/products/workstations/dgx-spark/)
[![Docs](https://img.shields.io/badge/Docs-readme.io-blue)](https://sip-agent.readme.io)

[![Build Status](https://github.com/CHA0S-CORP/general-disarray/actions/workflows/docker-build.yml/badge.svg)](https://github.com/CHA0S-CORP/general-disarray/actions/workflows/docker-build.yml)
[![Build Status](https://github.com/CHA0S-CORP/general-disarray/actions/workflows/docker-build-nvitop_exporter.yml/badge.svg)](https://github.com/CHA0S-CORP/general-disarray/actions/workflows/docker-build-nvitop_exporter.yml)

ğŸ“– **[Read the Documentation](https://sip-agent.readme.io)**

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ™ï¸ **Voice Conversations** | Natural speech-to-text and text-to-speech powered by Whisper & Kokoro |
| ğŸ¤– **LLM Integration** | Connects to OpenAI, vLLM, Ollama, LM Studio, and more |
| ğŸ”§ **Built-in Tools** | Weather, timers, callbacks, date/time, calculator, jokes |
| ğŸ”Œ **Plugin System** | Easily add custom tools with Python |
| ğŸŒ **REST API** | Initiate outbound calls, execute tools, manage schedules |
| â° **Scheduled Calls** | One-time or recurring calls (daily briefings, reminders) |
| ğŸ”— **Webhooks** | Trigger calls from Home Assistant, n8n, Grafana, and more |
| ğŸ—£ï¸ **Custom Phrases** | Customize greetings, goodbyes, and responses via JSON or env vars |
| ğŸ“Š **Observability** | Prometheus metrics, OpenTelemetry tracing, structured JSON logs |

## ğŸ’¡ Use Cases

| Use Case | Example |
|----------|---------|
| â²ï¸ **Timers & Reminders** | *"Set a timer for 10 minutes"* |
| ğŸ“ **Callbacks** | *"Call me back in an hour"* |
| ğŸŒ¤ï¸ **Weather Briefings** | Scheduled morning weather calls |
| ğŸ“… **Appointment Reminders** | Outbound calls with confirmation |
| ğŸš¨ **Alerts & Notifications** | Webhook-triggered phone calls |
| ğŸ  **Smart Home** | Voice control via phone |

---
## ğŸš€ Quick Example

Call the assistant and say:

> ğŸ—£ï¸ *"What's the weather like?"*

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ User
    participant Agent as ğŸ¤– SIP Agent
    participant STT as ğŸ¤ Speaches
    participant LLM as ğŸ§  LLM
    participant Tool as ğŸŒ¤ï¸ Weather Tool
    
    User->>Agent: "What's the weather like?"
    Agent->>STT: Audio stream
    STT-->>Agent: Transcribed text
    Agent->>LLM: User query + context
    LLM-->>Agent: [TOOL:WEATHER]
    Agent->>Tool: Execute
    Tool-->>Agent: Weather data
    Agent->>LLM: Tool result
    LLM-->>Agent: Natural response
    Agent->>STT: Text to speech
    STT-->>Agent: Audio
    Agent->>User: "At Storm Lake, it's 44Â°..."
```

**Assistant responds:**

> ğŸ¤– *"At Storm Lake, as of 9:30 pm, it's 44 degrees with foggy conditions. Wind is calm."*

![Example conversation flow](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20214959.png?raw=true)
<!-- TODO: Screenshot of log viewer showing a weather query conversation -->
---

## ğŸ—ï¸ Architecture

```mermaid
flowchart LR
    subgraph Caller
        Phone[ğŸ“± SIP Phone]
    end
    
    subgraph Agent["ğŸ¤– SIP AI Agent"]
        SIP[SIP Client]
        Audio[Audio Pipeline]
        Tools[Tool Manager]
        API[REST API]
    end
    
    subgraph Services
        LLM[ğŸ§  LLM Server<br/>OpenAI / vLLM / Ollama]
        Speaches[ğŸ¤ Speaches<br/>STT + TTS]
    end
    
    subgraph Integrations
        HA[ğŸ  Home Assistant]
        N8N[ğŸ”„ n8n]
        Webhook[ğŸ”— Webhooks]
    end
    
    Phone <-->|SIP/RTP| SIP
    SIP <--> Audio
    Audio <-->|Whisper| Speaches
    Audio <-->|Kokoro| Speaches
    Audio <--> Tools
    Tools <-->|OpenAI API| LLM
    
    API <--> Tools
    HA -->|HTTP| API
    N8N -->|HTTP| API
    Webhook -->|HTTP| API
```
---

## ğŸ”— Services & Integrations

| Service | Purpose | URL |
|---------|---------|-----|
| ğŸ¤– **SIP Agent** | AI Voice Assistant API | [localhost:8080](http://localhost:8080) |
| ğŸ¤ **Speaches** | STT/TTS (Whisper + Kokoro) | [localhost:8001](http://localhost:8001) |
| ğŸ§  **vLLM** | LLM Inference | [localhost:8000](http://localhost:8000) |
| ğŸ”´ **Redis** | Call Queue & Cache | `redis://localhost:6379` |
| ğŸ“Š **Prometheus** | Metrics Collection | [localhost:9090](http://localhost:9090) |
| ğŸ“ˆ **Grafana** | Dashboards | [localhost:3000](http://localhost:3000) |
| ğŸ“ **Loki** | Log Aggregation | [localhost:3100](http://localhost:3100) |
| ğŸ” **Tempo** | Distributed Tracing | [localhost:3200](http://localhost:3200) |
| ğŸ”„ **n8n** | Workflow Automation | [localhost:5678](http://localhost:5678) |
---

## ğŸš€ Quick Start

### Prerequisites

| Requirement | Description |
|-------------|-------------|
| ğŸ³ **Docker** | Docker and Docker Compose |
| ğŸ“ **SIP Server** | FreePBX, Asterisk, 3CX, or any SIP PBX |

### Installation

```bash
# Clone the repository
git clone https://github.com/your-org/sip-agent.git
cd sip-agent

# Configure environment
cp sip-agent/.env.example sip-agent/.env
nano sip-agent/.env

# Start services
docker compose up -d

# (Optional) Start services with Observability
docker compose -f ./docker-compose.yml -f docker-compose.observability.yml up -d
```

### Verify Installation

```bash
curl http://localhost:8080/health | jq
```

**Expected output:**

```json
{
  "status": "healthy",
  "sip_registered": true,
  "active_calls": 0
}
```

### Make a Test Call

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ INCOMING CALL                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¤– "Hello! Welcome to the AI assistant. How can I help?"  â”‚
â”‚ ğŸ‘¤ "What's the weather like?"                              â”‚
â”‚ ğŸ¤– "At Storm Lake, it's 44 degrees with foggy conditions."â”‚
â”‚ ğŸ‘¤ "Set a timer for 5 minutes"                             â”‚
â”‚ ğŸ¤– "Timer set for 5 minutes!"                             â”‚
â”‚ ğŸ‘¤ "Goodbye"                                               â”‚
â”‚ ğŸ¤– "Goodbye! Have a great day!"                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Configuration

Create a `.env` file with your settings:

```env
# ğŸ“ SIP Connection
SIP_USER=ai-assistant
SIP_PASSWORD=your-secure-password
SIP_DOMAIN=pbx.example.com

# ğŸ¤ Speaches (STT + TTS)
SPEACHES_API_URL=http://speaches:8001

# ğŸ§  LLM Settings
LLM_BASE_URL=http://vllm:8000/v1
LLM_MODEL=openai-community/gpt2-xl

# ğŸŒ¤ï¸ Weather (Optional)
TEMPEST_STATION_ID=12345
TEMPEST_API_TOKEN=your-api-token
```

ğŸ“– See [Configuration Reference](https://sip-agent.readme.io/docs/configuration) for all options.

---

## ğŸŒ API Examples

### ğŸ“ Make an Outbound Call

```bash
curl -X POST http://localhost:8080/call \
  -H "Content-Type: application/json" \
  -d '{
    "extension": "5551234567",
    "message": "Hello! This is a reminder about your appointment tomorrow."
  }'
```

**Response:**

```json
{
  "call_id": "out-1732945860-1",
  "status": "queued",
  "message": "Call initiated"
}
```
![](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20214700.png?raw=true)
### ğŸŒ… Morning Weather Briefing

Schedule a daily weather call at 7am:

```bash
curl -X POST http://sip-agent:8080/schedule \
  -H "Content-Type: application/json" \
  -d '{
    "extension": "5551234567",
    "tool": "WEATHER",
    "at_time": "07:00",
    "timezone": "America/Los_Angeles",
    "recurring": "daily",
    "prefix": "Good morning! Here is your weather update for today.",
    "suffix": "Have a great day!"
  }' | jq
```


**Response:**

```json
{
  "schedule_id": "a1b2c3d4",
  "status": "scheduled",
  "scheduled_for": "2025-12-01T07:00:00-08:00",
  "recurring": "daily"
}
```

### ğŸ”§ List Available Tools

```bash
curl http://localhost:8080/tools | jq '.[].name'
```

**Output:**

```
"WEATHER"
"SET_TIMER"
"CALLBACK"
"HANGUP"
"STATUS"
"CANCEL"
"DATETIME"
"CALC"
"JOKE"
```

---

## ğŸ§  Recommended Models

### NVIDIA H100 / A100 (80GB HBM)

Data center GPUs with maximum performance.

| Component | Model | Notes |
|-----------|-------|-------|
| **LLM** | `meta-llama/Llama-3.1-70B-Instruct` | Best quality, fits in single GPU |
| **LLM** | `Qwen/Qwen2.5-72B-Instruct` | Alternative, excellent reasoning |
| **STT** | `Systran/faster-whisper-large-v3` | Best accuracy |
| **TTS** | `af_heart` | Warm, natural voice |

```env
# H100/A100 80GB Configuration
LLM_MODEL=meta-llama/Llama-3.1-70B-Instruct
LLM_URL=http://localhost:8000/v1
STT_MODEL=Systran/faster-whisper-large-v3
TTS_VOICE=af_heart
```

---

### NVIDIA DGX Spark (128GB Unified)

Grace Blackwell GB10 with shared CPU/GPU memory.

| Component | Model | Notes |
|-----------|-------|-------|
| **LLM** | `meta-llama/Llama-3.1-70B-Instruct` | Fits in unified memory |
| **LLM** | `Qwen/Qwen2.5-72B-Instruct` | Alternative option |
| **LLM** | `deepseek-ai/DeepSeek-R1-Distill-Llama-70B` | Reasoning focused |
| **STT** | `Systran/faster-whisper-large-v3` | Best accuracy |
| **TTS** | `af_heart` | Warm, natural voice |

```env
# DGX Spark Configuration (128GB unified memory)
LLM_MODEL=meta-llama/Llama-3.1-70B-Instruct
LLM_URL=http://localhost:8000/v1
STT_MODEL=Systran/faster-whisper-large-v3
TTS_VOICE=af_heart
```

---

### NVIDIA RTX 5090 (32GB GDDR7)

Next-gen consumer flagship.

| Component | Model | Notes |
|-----------|-------|-------|
| **LLM** | `Qwen/Qwen2.5-32B-Instruct` | Best fit for 32GB |
| **LLM** | `meta-llama/Llama-3.1-8B-Instruct` | Faster, lower quality |
| **LLM** | `mistralai/Mistral-Small-24B-Instruct-2501` | Good balance |
| **STT** | `Systran/faster-whisper-large-v3` | Best accuracy |
| **TTS** | `af_heart` | Warm, natural voice |

```env
# RTX 5090 Configuration (32GB VRAM)
LLM_MODEL=Qwen/Qwen2.5-32B-Instruct
LLM_URL=http://localhost:8000/v1
STT_MODEL=Systran/faster-whisper-large-v3
TTS_VOICE=af_heart
```

---

### NVIDIA RTX 4090 (24GB GDDR6X)

Current consumer flagship.

| Component | Model | Notes |
|-----------|-------|-------|
| **LLM** | `Qwen/Qwen2.5-14B-Instruct` | Best quality for 24GB |
| **LLM** | `meta-llama/Llama-3.1-8B-Instruct` | Faster option |
| **LLM** | `mistralai/Mistral-7B-Instruct-v0.3` | Good tool calling |
| **STT** | `Systran/faster-whisper-large-v3` | Best accuracy |
| **TTS** | `af_heart` | Warm, natural voice |

```env
# RTX 4090 Configuration (24GB VRAM)
LLM_MODEL=Qwen/Qwen2.5-14B-Instruct
LLM_URL=http://localhost:8000/v1
STT_MODEL=Systran/faster-whisper-large-v3
TTS_VOICE=af_heart
```

---

### NVIDIA RTX 3090 / 4080 (24GB / 16GB)

High-end consumer GPUs.

| Component | Model | Notes |
|-----------|-------|-------|
| **LLM** | `meta-llama/Llama-3.1-8B-Instruct` | Best for 16-24GB |
| **LLM** | `Qwen/Qwen2.5-7B-Instruct` | Fast alternative |
| **LLM** | `microsoft/Phi-3-medium-4k-instruct` | 14B, good quality |
| **STT** | `Systran/faster-whisper-medium` | Good balance |
| **TTS** | `af_heart` | Warm, natural voice |

```env
# RTX 3090/4080 Configuration (16-24GB VRAM)
LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
LLM_URL=http://localhost:8000/v1
STT_MODEL=Systran/faster-whisper-medium
TTS_VOICE=af_heart
```

---

### NVIDIA RTX 3080 / 4070 (10-12GB)

Mid-range GPUs.

| Component | Model | Notes |
|-----------|-------|-------|
| **LLM** | `Qwen/Qwen2.5-7B-Instruct` | Best for 10-12GB |
| **LLM** | `microsoft/Phi-3-mini-4k-instruct` | 3.8B, very fast |
| **LLM** | `meta-llama/Llama-3.2-3B-Instruct` | Lightweight |
| **STT** | `Systran/faster-whisper-small` | Low VRAM |
| **TTS** | `af_heart` | Warm, natural voice |

```env
# RTX 3080/4070 Configuration (10-12GB VRAM)
LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
LLM_URL=http://localhost:8000/v1
STT_MODEL=Systran/faster-whisper-small
TTS_VOICE=af_heart
```

---

### Low-Latency Stack (Any GPU)

Optimized for fastest response times.

```env
# Minimum latency configuration
LLM_MODEL=Qwen/Qwen2.5-3B-Instruct
STT_MODEL=Systran/faster-whisper-tiny.en
TTS_VOICE=af_heart
TTS_SPEED=1.1
```

---

### TTS Voice Options

| Voice | Style | Gender | Accent |
|-------|-------|--------|--------|
| `af_heart` | Warm, friendly | Female | American |
| `af_bella` | Professional | Female | American |
| `af_sarah` | Casual | Female | American |
| `af_nicole` | Expressive | Female | American |
| `am_adam` | Neutral | Male | American |
| `am_michael` | Professional | Male | American |
| `bf_emma` | Warm | Female | British |
| `bm_george` | Professional | Male | British |

---

## ğŸ”§ Built-in Tools

| Tool | Description | Example Phrase |
|------|-------------|----------------|
| ğŸŒ¤ï¸ `WEATHER` | Current weather conditions | *"What's the weather?"* |
| â²ï¸ `SET_TIMER` | Set a countdown timer | *"Set a timer for 5 minutes"* |
| ğŸ“ `CALLBACK` | Schedule a callback | *"Call me back in an hour"* |
| ğŸ“´ `HANGUP` | End the call | *"Goodbye"* |
| ğŸ“‹ `STATUS` | Check pending timers | *"What timers do I have?"* |
| âŒ `CANCEL` | Cancel timers/callbacks | *"Cancel my timer"* |
| ğŸ• `DATETIME` | Current date and time | *"What time is it?"* |
| ğŸ§® `CALC` | Math calculations | *"What's 25 times 4?"* |
| ğŸ˜„ `JOKE` | Tell a joke | *"Tell me a joke"* |
| ğŸ¦œ `SIMON_SAYS` | Repeat back verbatim | *"Simon says hello world"* |

---

## ğŸ”Œ Creating Plugins

Add custom tools by creating Python plugins:

```python
# src/plugins/hello_tool.py
from tool_plugins import BaseTool, ToolResult, ToolStatus

class HelloTool(BaseTool):
    name = "HELLO"
    description = "Say hello to someone"
    
    parameters = {
        "name": {
            "type": "string",
            "description": "Name to greet",
            "required": True
        }
    }
    
    async def execute(self, params):
        name = params.get("name", "friend")
        return ToolResult(
            status=ToolStatus.SUCCESS,
            message=f"Hello, {name}! Nice to meet you."
        )
```

Register in `tool_manager.py`:

```python
from plugins.hello_tool import HelloTool

tool_classes = [
    # ... existing tools ...
    HelloTool,
]
```

ğŸ“– See [Creating Plugins](https://sip-agent.readme.io/docs/plugins) for the full guide.

---

## ğŸ“Š Monitoring

### View Logs

```bash
# Docker logs
docker logs -f sip-agent

# Formatted log viewer
python tools/view-logs.py -f
```

**Example output:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ ğŸ“ CALL #1 - From: 1001
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
15:30:05  ğŸ“ Call started
15:30:06  ğŸ‘¤ "What's the weather?"
15:30:07  ğŸ”§ [TOOL:WEATHER]
15:30:08  ğŸ¤– "At Storm Lake, it's 44 degrees..."
15:30:12  ğŸ‘¤ "Thanks, goodbye"
15:30:13  ğŸ“´ Call ended (duration: 0:08)
```

### Grafana Dashboard

Import the included dashboard:

```bash
grafana/dashboards/sip-agent.json
```

![Alt text](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20222658.png?raw=true "Dashboard")
![Alt text](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20222729.png?raw=true "Dashboard")
![Alt text](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20222739.png?raw=true "Dashboard")
![Alt text](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20222748.png?raw=true "Dashboard")
![Alt text](https://github.com/MaxwellDPS/docs/blob/v1.0/photos/Screenshot%202025-11-29%20222808.png?raw=true "Dashboard")


---

## ğŸ—‚ï¸ Project Structure

```
sip-agent/
â”œâ”€â”€ ğŸ“„ README.md                    # ğŸ‘ˆ You are here
â”œâ”€â”€ ğŸ“„ RELEASE.md                   # Release notes
â”œâ”€â”€ ğŸ“„ CHANGELOG.md                 # Version history
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Main compose file
â”œâ”€â”€ ğŸ“„ docker-compose.observability.yml
â”œâ”€â”€ ğŸ“„ openapi.yaml                 # API specification
â”‚
â”œâ”€â”€ ğŸ“‚ sip-agent/                   # Core application
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
â”‚   â”œâ”€â”€ ğŸ“„ .env.example
â”‚   â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”‚   â””â”€â”€ ğŸ“„ phrases.json.example
â”‚   â””â”€â”€ ğŸ“‚ src/
â”‚       â”œâ”€â”€ ğŸ“„ main.py              # Application entry
â”‚       â”œâ”€â”€ ğŸ“„ config.py            # Configuration
â”‚       â”œâ”€â”€ ğŸ“„ api.py               # REST API
â”‚       â”œâ”€â”€ ğŸ“„ sip_handler.py       # SIP call handling
â”‚       â”œâ”€â”€ ğŸ“„ audio_pipeline.py    # STT/TTS processing
â”‚       â”œâ”€â”€ ğŸ“„ llm_engine.py        # LLM integration
â”‚       â”œâ”€â”€ ğŸ“„ tool_manager.py      # Tool orchestration
â”‚       â”œâ”€â”€ ğŸ“„ tool_plugins.py      # Plugin base classes
â”‚       â”œâ”€â”€ ğŸ“„ call_queue.py        # Redis call queue
â”‚       â”œâ”€â”€ ğŸ“„ realtime_client.py   # WebSocket STT
â”‚       â”œâ”€â”€ ğŸ“„ telemetry.py         # OpenTelemetry
â”‚       â”œâ”€â”€ ğŸ“„ logging_utils.py     # Structured logging
â”‚       â”œâ”€â”€ ğŸ“„ retry_utils.py       # API retry logic
â”‚       â””â”€â”€ ğŸ“‚ plugins/             # Built-in tools
â”‚           â”œâ”€â”€ ğŸ“„ weather_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ timer_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ callback_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ hangup_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ status_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ cancel_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ datetime_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ calc_tool.py
â”‚           â”œâ”€â”€ ğŸ“„ joke_tool.py
â”‚           â””â”€â”€ ğŸ“„ simon_says_tool.py
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                        # Documentation
â”‚   â”œâ”€â”€ ğŸ“„ index.md                 # Overview
â”‚   â”œâ”€â”€ ğŸ“„ getting-started.md       # Installation
â”‚   â”œâ”€â”€ ğŸ“„ configuration.md         # Config reference
â”‚   â”œâ”€â”€ ğŸ“„ api-reference.md         # REST API
â”‚   â”œâ”€â”€ ğŸ“„ tools.md                 # Built-in tools
â”‚   â”œâ”€â”€ ğŸ“„ plugins.md               # Plugin development
â”‚   â”œâ”€â”€ ğŸ“„ examples.md              # Integration examples
â”‚   â””â”€â”€ ğŸ“‚ screenshots/
â”‚
â”œâ”€â”€ ğŸ“‚ observability/               # Monitoring stack
â”‚   â”œâ”€â”€ ğŸ“‚ grafana/
â”‚   â”‚   â””â”€â”€ ğŸ“‚ provisioning/
â”‚   â”‚       â”œâ”€â”€ ğŸ“‚ dashboards/      # Pre-built dashboards
â”‚   â”‚       â””â”€â”€ ğŸ“‚ datasources/
â”‚   â”œâ”€â”€ ğŸ“‚ prometheus/
â”‚   â”‚   â””â”€â”€ ğŸ“„ prometheus.yaml
â”‚   â”œâ”€â”€ ğŸ“‚ loki/
â”‚   â”‚   â””â”€â”€ ğŸ“„ loki.yaml
â”‚   â”œâ”€â”€ ğŸ“‚ tempo/
â”‚   â”‚   â””â”€â”€ ğŸ“„ tempo.yaml
â”‚   â””â”€â”€ ğŸ“‚ otel-collector/
â”‚       â””â”€â”€ ğŸ“„ config.yaml
â”‚
â”œâ”€â”€ ğŸ“‚ tools/                       # Utilities
â”‚   â””â”€â”€ ğŸ“„ view-logs.py             # Log viewer
â”‚
â””â”€â”€ ğŸ“‚ .github/
    â””â”€â”€ ğŸ“‚ workflows/
        â”œâ”€â”€ ğŸ“„ docker-build.yml     # Docker CI
        â””â”€â”€ ğŸ“„ readme-sync.yml      # Docs sync
```

---

## ğŸ–¥ï¸ Runs on NVIDIA DGX Spark

This project is optimized to run on the [NVIDIA DGX Spark](https://www.nvidia.com/en-us/products/workstations/dgx-spark/) with Grace Blackwell architecture.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¢ NVIDIA DGX Spark                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ§  Grace Blackwell GB10 Superchip                          â”‚
â”‚ ğŸ’¾ 128GB Unified Memory                                     â”‚
â”‚ âš¡ 1 PFLOP AI Performance                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… Local LLM inference (vLLM, Ollama)                      â”‚
â”‚ âœ… Local STT/TTS (Speaches + Whisper + Kokoro)             â”‚
â”‚ âœ… Real-time voice processing                               â”‚
â”‚ âœ… Multiple concurrent calls                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Recommended DGX Spark setup:**

```env
# Run everything locally on DGX Spark
LLM_BASE_URL=http://localhost:8000/v1
LLM_MODEL=openai/gpt-oss-20b
SPEACHES_API_URL=http://localhost:8001
```

---

## ğŸ“– Documentation

**ğŸ“š Full documentation available at [sip-agent.readme.io](https://sip-agent.readme.io)**

| Document | Description |
|----------|-------------|
| [ğŸ“– Overview](https://sip-agent.readme.io/docs/overview) | Architecture and features |
| [ğŸš€ Getting Started](https://sip-agent.readme.io/docs/getting-started) | Installation guide |
| [âš™ï¸ Configuration](https://sip-agent.readme.io/docs/configuration) | Environment variables |
| [ğŸŒ API Reference](https://sip-agent.readme.io/docs/api-reference) | REST API endpoints |
| [ğŸ”§ Built-in Tools](https://sip-agent.readme.io/docs/tools) | Available tools |
| [ğŸ”Œ Creating Plugins](https://sip-agent.readme.io/docs/plugins) | Custom tool development |
| [ğŸ“– Examples](https://sip-agent.readme.io/docs/examples) | Integration patterns |

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines first.

```bash
# Fork and clone
git clone https://github.com/your-username/sip-agent.git

# Create branch
git checkout -b feature/amazing-feature

# Make changes and test
docker compose up -d
python -m pytest

# Commit with emoji
git commit -m "âœ¨ feat: add amazing feature"

# Push and PR
git push origin feature/amazing-feature
```


---

## ğŸ“œ License

This project is licensed under the GNU Affero General Public License v3.0 - see the [LICENSE](LICENSE) file for details.

```
SPDX-License-Identifier: AGPL-3.0-or-later
```

---

## ğŸ™ Acknowledgments

- [NVIDIA DGX Spark](https://www.nvidia.com/en-us/products/workstations/dgx-spark/) â€” AI supercomputer platform
- [Speaches](https://github.com/speaches-ai/speaches) â€” Unified STT/TTS server
- [PJSIP](https://www.pjsip.org/) â€” SIP stack
- [FastAPI](https://fastapi.tiangolo.com/) â€” REST API framework
- [WeatherFlow Tempest](https://tempestwx.com/) â€” Weather data

---

## ğŸ“ Support

| Resource | Link |
|----------|------|
| ğŸ“– Docs | **[sip-agent.readme.io](https://sip-agent.readme.io)** |
| ğŸ› Issues | [GitHub Issues](https://github.com/your-org/sip-agent/issues) |
| ğŸ’¬ Discussions | [GitHub Discussions](https://github.com/your-org/sip-agent/discussions) |

---

<p align="center">
  Made with â¤ï¸ and ğŸ¤–
</p>
